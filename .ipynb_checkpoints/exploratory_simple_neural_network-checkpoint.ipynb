{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e9c1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b06d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "    \n",
    "    # 2 layer neural network:\n",
    "    # First layer has as a node for each feature \n",
    "    # Second layer has four nodes\n",
    "    def __init__(self, features, labels, learning_rate, second_layer_size):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layer_1_weights = np.random.rand(features[0].size, second_layer_size)\n",
    "        self.layer_2_weights = np.random.rand(second_layer_size, 1)\n",
    "    \n",
    "    # Signmoid activation function\n",
    "    def activation_function(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    # Used for gradient descent\n",
    "    def activation_function_derivative(self, x):\n",
    "        return self.activation_function(x)*(1-self.activation_function(x))\n",
    "    \n",
    "    def set_error(self):\n",
    "        self.error = (self.layer_2_results - self.labels)\n",
    "    \n",
    "    def set_mean_squared_error(self):\n",
    "        self.mean_squared_error = np.sum(np.square(self.error))/self.error.size \n",
    "        \n",
    "    # Calculates the expected value\n",
    "    def feedforward(self):\n",
    "        self.layer_1_results = self.activation_function(np.dot(self.features, self.layer_1_weights))\n",
    "        self.layer_2_results = self.activation_function(np.dot(self.layer_1_results, self.layer_2_weights))\n",
    "        self.set_error()\n",
    "        self.set_mean_squared_error() \n",
    "    \n",
    "    # Use Mean squared errors for loss function\n",
    "    # TODO: Double check these derivates, include math here for future reference, and simplify code\n",
    "    def backpropagate(self):\n",
    "        layer_2_weights_change = (2/self.error.size)*self.error*np.dot(self.layer_1_results, self.activation_function_derivative(self.layer_2_results))\n",
    "        layer_1_weights_change = (2/self.error.size)*(self.features.T).dot(self.error*self.activation_function_derivative(self.layer_2_results)).dot(self.layer_2_weights.T).dot(self.activation_function_derivative(self.layer_1_results))\n",
    "                \n",
    "        self.layer_2_weights += self.learning_rate*layer_2_weights_change\n",
    "        self.layer_1_weights += self.learning_rate*layer_1_weights_change\n",
    "    \n",
    "    def train(self):\n",
    "        self.feedforward()\n",
    "        print(\"MSE = {}\".format(self.mean_squared_error))\n",
    "        self.backpropagate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d72205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "MSE = 0.16622556475403755\n",
      "Iteration: 1\n",
      "MSE = 0.16669208283269218\n",
      "Iteration: 2\n",
      "MSE = 0.16716101748857048\n",
      "Iteration: 3\n",
      "MSE = 0.16763237833591577\n",
      "Iteration: 4\n",
      "MSE = 0.16810617489553736\n",
      "Iteration: 5\n",
      "MSE = 0.16858241658997122\n",
      "Iteration: 6\n",
      "MSE = 0.169061112738523\n",
      "Iteration: 7\n",
      "MSE = 0.16954227255219267\n",
      "Iteration: 8\n",
      "MSE = 0.17002590512847976\n",
      "Iteration: 9\n",
      "MSE = 0.1705120194460685\n",
      "Iteration: 10\n",
      "MSE = 0.17100062435939317\n",
      "Iteration: 11\n",
      "MSE = 0.1714917285930815\n",
      "Iteration: 12\n",
      "MSE = 0.171985340736278\n",
      "Iteration: 13\n",
      "MSE = 0.17248146923684446\n",
      "Iteration: 14\n",
      "MSE = 0.17298012239544033\n",
      "Iteration: 15\n",
      "MSE = 0.1734813083594808\n",
      "Iteration: 16\n",
      "MSE = 0.17398503511697355\n",
      "Iteration: 17\n",
      "MSE = 0.17449131049023536\n",
      "Iteration: 18\n",
      "MSE = 0.17500014212948783\n",
      "Iteration: 19\n",
      "MSE = 0.17551153750633336\n",
      "Iteration: 20\n",
      "MSE = 0.17602550390711283\n",
      "Iteration: 21\n",
      "MSE = 0.17654204842614496\n",
      "Iteration: 22\n",
      "MSE = 0.17706117795884996\n",
      "Iteration: 23\n",
      "MSE = 0.17758289919475678\n",
      "Iteration: 24\n",
      "MSE = 0.17810721861039813\n",
      "Iteration: 25\n",
      "MSE = 0.17863414246209305\n",
      "Iteration: 26\n",
      "MSE = 0.17916367677862027\n",
      "Iteration: 27\n",
      "MSE = 0.1796958273537831\n",
      "Iteration: 28\n",
      "MSE = 0.1802305997388712\n",
      "Iteration: 29\n",
      "MSE = 0.18076799923501785\n",
      "Iteration: 30\n",
      "MSE = 0.18130803088545963\n",
      "Iteration: 31\n",
      "MSE = 0.18185069946769863\n",
      "Iteration: 32\n",
      "MSE = 0.18239600948557255\n",
      "Iteration: 33\n",
      "MSE = 0.18294396516123523\n",
      "Iteration: 34\n",
      "MSE = 0.1834945704270522\n",
      "Iteration: 35\n",
      "MSE = 0.1840478289174144\n",
      "Iteration: 36\n",
      "MSE = 0.184603743960476\n",
      "Iteration: 37\n",
      "MSE = 0.18516231856981968\n",
      "Iteration: 38\n",
      "MSE = 0.1857235554360547\n",
      "Iteration: 39\n",
      "MSE = 0.18628745691835344\n",
      "Iteration: 40\n",
      "MSE = 0.18685402503593102\n",
      "Iteration: 41\n",
      "MSE = 0.1874232614594748\n",
      "Iteration: 42\n",
      "MSE = 0.18799516750252884\n",
      "Iteration: 43\n",
      "MSE = 0.1885697441128399\n",
      "Iteration: 44\n",
      "MSE = 0.18914699186367204\n",
      "Iteration: 45\n",
      "MSE = 0.18972691094509644\n",
      "Iteration: 46\n",
      "MSE = 0.1903095011552628\n",
      "Iteration: 47\n",
      "MSE = 0.19089476189166066\n",
      "Iteration: 48\n",
      "MSE = 0.19148269214237815\n",
      "Iteration: 49\n",
      "MSE = 0.19207329047736582\n",
      "Iteration: 50\n",
      "MSE = 0.1926665550397135\n",
      "Iteration: 51\n",
      "MSE = 0.19326248353694916\n",
      "Iteration: 52\n",
      "MSE = 0.19386107323236865\n",
      "Iteration: 53\n",
      "MSE = 0.19446232093640375\n",
      "Iteration: 54\n",
      "MSE = 0.19506622299803977\n",
      "Iteration: 55\n",
      "MSE = 0.1956727752962901\n",
      "Iteration: 56\n",
      "MSE = 0.19628197323173885\n",
      "Iteration: 57\n",
      "MSE = 0.19689381171816026\n",
      "Iteration: 58\n",
      "MSE = 0.19750828517422525\n",
      "Iteration: 59\n",
      "MSE = 0.19812538751530517\n",
      "Iteration: 60\n",
      "MSE = 0.19874511214538337\n",
      "Iteration: 61\n",
      "MSE = 0.19936745194908398\n",
      "Iteration: 62\n",
      "MSE = 0.19999239928382986\n",
      "Iteration: 63\n",
      "MSE = 0.20061994597213906\n",
      "Iteration: 64\n",
      "MSE = 0.20125008329407154\n",
      "Iteration: 65\n",
      "MSE = 0.20188280197983596\n",
      "Iteration: 66\n",
      "MSE = 0.2025180922025684\n",
      "Iteration: 67\n",
      "MSE = 0.20315594357129324\n",
      "Iteration: 68\n",
      "MSE = 0.20379634512407696\n",
      "Iteration: 69\n",
      "MSE = 0.204439285321386\n",
      "Iteration: 70\n",
      "MSE = 0.2050847520396599\n",
      "Iteration: 71\n",
      "MSE = 0.2057327325651094\n",
      "Iteration: 72\n",
      "MSE = 0.20638321358775058\n",
      "Iteration: 73\n",
      "MSE = 0.20703618119568612\n",
      "Iteration: 74\n",
      "MSE = 0.20769162086964293\n",
      "Iteration: 75\n",
      "MSE = 0.20834951747777733\n",
      "Iteration: 76\n",
      "MSE = 0.20900985527075647\n",
      "Iteration: 77\n",
      "MSE = 0.2096726178771274\n",
      "Iteration: 78\n",
      "MSE = 0.21033778829898084\n",
      "Iteration: 79\n",
      "MSE = 0.2110053489079213\n",
      "Iteration: 80\n",
      "MSE = 0.21167528144135003\n",
      "Iteration: 81\n",
      "MSE = 0.2123475669990703\n",
      "Iteration: 82\n",
      "MSE = 0.21302218604022372\n",
      "Iteration: 83\n",
      "MSE = 0.21369911838056255\n",
      "Iteration: 84\n",
      "MSE = 0.21437834319006793\n",
      "Iteration: 85\n",
      "MSE = 0.21505983899091893\n",
      "Iteration: 86\n",
      "MSE = 0.215743583655818\n",
      "Iteration: 87\n",
      "MSE = 0.2164295544066808\n",
      "Iteration: 88\n",
      "MSE = 0.2171177278136918\n",
      "Iteration: 89\n",
      "MSE = 0.2178080797947323\n",
      "Iteration: 90\n",
      "MSE = 0.21850058561518407\n",
      "Iteration: 91\n",
      "MSE = 0.21919521988811067\n",
      "Iteration: 92\n",
      "MSE = 0.21989195657481964\n",
      "Iteration: 93\n",
      "MSE = 0.22059076898580673\n",
      "Iteration: 94\n",
      "MSE = 0.22129162978208258\n",
      "Iteration: 95\n",
      "MSE = 0.22199451097688244\n",
      "Iteration: 96\n",
      "MSE = 0.22269938393775807\n",
      "Iteration: 97\n",
      "MSE = 0.22340621938905\n",
      "Iteration: 98\n",
      "MSE = 0.22411498741473826\n",
      "Iteration: 99\n",
      "MSE = 0.22482565746166772\n"
     ]
    }
   ],
   "source": [
    "# Input features\n",
    "features = np.array([[-3,-3],\n",
    "                     [-3,3],\n",
    "                     [3,-3],\n",
    "                     [3,3]])\n",
    "\n",
    "labels = np.array([[1], [0], [1], [1]])\n",
    "\n",
    "simple_neural_network = SimpleNeuralNetwork(features, labels, 0.01, 4)\n",
    "\n",
    "for iteration in range(100):\n",
    "    print(\"Iteration: {}\".format(iteration))\n",
    "    simple_neural_network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29e55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
